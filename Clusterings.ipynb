{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import math\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = gensim.models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)  \n",
    "stop_words =  set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(path):\n",
    "    with open(path) as file:\n",
    "        lines = file.read().replace('\\n', '')\n",
    "    \n",
    "    return nltk.sent_tokenize(lines)\n",
    "\n",
    "def filter_sentence(sentence):\n",
    "    tokens = gensim.utils.simple_preprocess(sentence)#nltk.tokenize.word_tokenize(sentence)\n",
    "    filtered = [w.lower() for w in tokens if not w in stop_words and w in word_model.vocab]\n",
    "    return filtered\n",
    "\n",
    "def get_sentence_embedding(sentence):\n",
    "    vectors = np.zeros((len(sentence),300))\n",
    "    for i, word in enumerate(sentence):\n",
    "        embedding = word_model[word]\n",
    "        assert np.all(np.isfinite(embedding))\n",
    "        vectors[i] = embedding\n",
    "    mean = np.mean(vectors, axis=0)\n",
    "    return mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(path):\n",
    "    sentences = get_sentences(path)\n",
    "    embeddings = []\n",
    "    for s in sentences:\n",
    "        filtered = filter_sentence(s)\n",
    "        if not len(filtered)==0:\n",
    "            embedded = get_sentence_embedding(filtered)\n",
    "            embeddings.append(embedded)\n",
    "    \n",
    "    embeddings_array = np.zeros((len(embeddings), 300))\n",
    "    for i,e in enumerate(embeddings):\n",
    "        embeddings_array[i] = e\n",
    "    return embeddings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_embeddings(embeddings, components=150):\n",
    "    \n",
    "    covar =  PCA(n_components=components)\n",
    "    reduced = covar.fit_transform(embeddings)\n",
    "    return reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_vector(vectors):\n",
    "    #vectors are in a list\n",
    "    assert not len(vectors)==0\n",
    "    \n",
    "    first = np.zeros(vectors[0].shape)\n",
    "    for v in vectors:\n",
    "        first+=v\n",
    "    return first/(len(vectors))\n",
    "\n",
    "def get_representatives(clusters, cluster_groups):\n",
    "    \n",
    "    representatives = []\n",
    "    \n",
    "    for i, cluster in enumerate(clusters):\n",
    "        \n",
    "        min_dist = np.inf\n",
    "        index = -1\n",
    "        for j, v in enumerate(cluster_groups[i]):\n",
    "            dist = np.sum((v-cluster)**2)\n",
    "            if dist < min_dist:\n",
    "                min_dist=dist\n",
    "                index = j\n",
    "        representatives.append(cluster_groups[i][index])\n",
    "    return representatives\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(vectors, num_clusters=10, iterations=10):\n",
    "    \n",
    "    #initialize clusters to random points\n",
    "    clusters = vectors[np.random.choice(vectors.shape[0], num_clusters, replace=False)]\n",
    "    new_clusters = clusters\n",
    "    for j in range(iterations):\n",
    "        clusters = new_clusters\n",
    "        # list of vectors belonging to each cluster\n",
    "        cluster_groups = [[] for cluster in clusters]\n",
    "        for i in range(vectors.shape[0]):\n",
    "            vector = vectors[i]\n",
    "\n",
    "            min_dist = np.inf\n",
    "            index = -1\n",
    "            for i,cluster in enumerate(clusters):\n",
    "                dist = np.sum( (vector-cluster)**2)\n",
    "                if dist < min_dist:\n",
    "                    min_dist = dist \n",
    "                    index = i\n",
    "            \n",
    "            # add to group of closest cluster\n",
    "            cluster_groups[index].append(vector)\n",
    "        print(\"Iteration:\", j, [len(c) for c in cluster_groups])\n",
    "        new_clusters = [mean_vector(group) for group in cluster_groups]\n",
    "        \n",
    "        diff = [new for i,new in enumerate(new_clusters) if not np.array_equal(new, clusters[i])]\n",
    "        if len(diff)==0:\n",
    "            break\n",
    "    return clusters, cluster_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = reduce_embeddings(embed_text(\"bible.txt\"), components=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 [275, 511, 306, 83, 19, 154, 58, 21, 7, 9, 143, 45, 198, 61, 1681, 168, 118, 152, 977, 181]\n",
      "Iteration: 1 [325, 574, 384, 109, 42, 186, 170, 35, 13, 9, 189, 39, 213, 50, 1403, 137, 157, 186, 773, 173]\n",
      "Iteration: 2 [263, 671, 404, 116, 44, 153, 214, 46, 33, 10, 303, 38, 289, 39, 1156, 96, 203, 206, 725, 158]\n",
      "Iteration: 3 [186, 728, 429, 130, 50, 110, 212, 50, 46, 10, 388, 35, 320, 37, 1022, 78, 253, 232, 693, 158]\n",
      "Iteration: 4 [144, 771, 444, 141, 54, 86, 212, 52, 55, 10, 413, 31, 337, 34, 961, 75, 289, 245, 649, 164]\n",
      "Iteration: 5 [121, 782, 453, 156, 56, 76, 212, 52, 56, 10, 434, 32, 331, 32, 960, 75, 312, 242, 612, 163]\n",
      "Iteration: 6 [109, 793, 452, 174, 53, 71, 209, 53, 60, 10, 449, 34, 324, 30, 981, 75, 320, 234, 575, 161]\n",
      "Iteration: 7 [108, 811, 447, 182, 54, 67, 208, 55, 60, 10, 461, 34, 324, 27, 995, 75, 318, 219, 554, 158]\n",
      "Iteration: 8 [109, 828, 445, 180, 54, 64, 207, 55, 58, 10, 467, 34, 320, 24, 1011, 75, 319, 211, 540, 156]\n",
      "Iteration: 9 [109, 842, 447, 182, 54, 62, 202, 55, 56, 10, 474, 34, 320, 23, 1025, 75, 322, 203, 521, 151]\n",
      "Iteration: 10 [109, 852, 445, 175, 54, 61, 200, 55, 56, 10, 479, 34, 320, 23, 1039, 75, 324, 199, 508, 149]\n",
      "Iteration: 11 [109, 868, 439, 175, 54, 60, 200, 55, 56, 10, 480, 34, 321, 23, 1054, 75, 329, 195, 488, 142]\n",
      "Iteration: 12 [109, 887, 428, 176, 54, 60, 202, 55, 56, 10, 487, 34, 322, 22, 1061, 75, 332, 194, 466, 137]\n",
      "Iteration: 13 [109, 901, 416, 175, 55, 61, 202, 55, 56, 10, 491, 34, 326, 22, 1079, 75, 333, 194, 440, 133]\n",
      "Iteration: 14 [109, 913, 403, 174, 56, 61, 201, 55, 56, 10, 496, 34, 330, 22, 1093, 75, 336, 194, 417, 132]\n",
      "Iteration: 15 [109, 923, 400, 174, 56, 61, 201, 55, 56, 10, 501, 33, 333, 22, 1098, 76, 342, 194, 394, 129]\n",
      "Iteration: 16 [109, 921, 399, 174, 56, 61, 200, 55, 55, 10, 504, 33, 337, 22, 1109, 76, 349, 195, 373, 129]\n",
      "Iteration: 17 [109, 919, 397, 174, 56, 61, 200, 55, 55, 10, 505, 33, 341, 22, 1124, 76, 350, 194, 358, 128]\n",
      "Iteration: 18 [109, 922, 396, 174, 56, 61, 200, 55, 55, 10, 503, 33, 344, 22, 1135, 76, 353, 194, 342, 127]\n",
      "Iteration: 19 [109, 916, 398, 174, 56, 61, 198, 55, 55, 10, 505, 32, 346, 22, 1145, 76, 356, 193, 332, 128]\n",
      "Iteration: 20 [109, 912, 399, 174, 56, 61, 196, 55, 55, 10, 508, 29, 348, 22, 1153, 76, 356, 192, 328, 128]\n",
      "Iteration: 21 [109, 916, 395, 174, 56, 61, 195, 55, 55, 10, 508, 28, 349, 22, 1163, 76, 357, 191, 319, 128]\n",
      "Iteration: 22 [109, 910, 392, 174, 56, 61, 194, 55, 55, 10, 509, 28, 351, 22, 1173, 76, 359, 191, 314, 128]\n",
      "Iteration: 23 [109, 906, 390, 174, 56, 61, 193, 55, 55, 10, 511, 28, 353, 22, 1179, 76, 361, 191, 310, 127]\n",
      "Iteration: 24 [109, 902, 391, 174, 56, 61, 192, 55, 55, 10, 513, 28, 354, 22, 1177, 76, 365, 191, 309, 127]\n",
      "Iteration: 25 [109, 895, 390, 175, 56, 61, 191, 55, 55, 10, 513, 28, 354, 22, 1181, 76, 370, 191, 308, 127]\n",
      "Iteration: 26 [109, 887, 390, 175, 56, 61, 191, 55, 55, 10, 512, 28, 355, 22, 1185, 76, 374, 191, 308, 127]\n",
      "Iteration: 27 [109, 877, 392, 176, 56, 61, 191, 55, 55, 10, 514, 28, 354, 22, 1190, 76, 377, 191, 306, 127]\n",
      "Iteration: 28 [109, 868, 392, 178, 56, 61, 191, 55, 55, 10, 513, 28, 353, 22, 1195, 76, 382, 191, 305, 127]\n",
      "Iteration: 29 [109, 857, 392, 180, 56, 61, 190, 55, 55, 10, 518, 28, 353, 22, 1197, 76, 383, 192, 305, 128]\n",
      "Iteration: 30 [109, 850, 392, 182, 56, 61, 190, 55, 55, 10, 521, 28, 354, 22, 1197, 76, 384, 192, 306, 127]\n",
      "Iteration: 31 [109, 847, 392, 183, 56, 61, 190, 55, 55, 10, 522, 28, 354, 22, 1197, 76, 385, 192, 306, 127]\n",
      "Iteration: 32 [109, 845, 392, 184, 56, 61, 190, 55, 55, 10, 523, 28, 354, 22, 1196, 76, 386, 193, 305, 127]\n",
      "Iteration: 33 [109, 844, 393, 184, 56, 61, 190, 55, 55, 10, 523, 28, 353, 22, 1195, 76, 385, 195, 306, 127]\n",
      "Iteration: 34 [109, 843, 392, 184, 56, 61, 190, 55, 55, 10, 523, 28, 356, 22, 1191, 76, 389, 195, 305, 127]\n",
      "Iteration: 35 [109, 836, 393, 184, 56, 61, 190, 55, 55, 10, 523, 28, 359, 22, 1191, 76, 391, 196, 305, 127]\n",
      "Iteration: 36 [109, 833, 392, 184, 56, 61, 190, 55, 55, 10, 523, 28, 363, 22, 1188, 76, 395, 196, 304, 127]\n",
      "Iteration: 37 [109, 828, 393, 185, 56, 61, 189, 55, 55, 10, 522, 28, 366, 22, 1188, 76, 399, 195, 303, 127]\n",
      "Iteration: 38 [109, 823, 393, 185, 56, 61, 188, 55, 55, 10, 523, 28, 370, 22, 1187, 76, 402, 195, 302, 127]\n",
      "Iteration: 39 [109, 817, 394, 186, 56, 61, 187, 55, 55, 10, 526, 28, 373, 22, 1186, 76, 405, 195, 299, 127]\n"
     ]
    }
   ],
   "source": [
    "clusters, groups = kmeans_clustering(embeddings, num_clusters=20, iterations=40)\n",
    "reps = get_representatives(clusters, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
